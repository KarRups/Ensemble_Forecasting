{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a05aa4b-654b-4756-9e59-00a695cd3c38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Downloading Necessary Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7bb2e-1c16-4ee0-a39b-4f9b0aa9f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Geospatial\n",
    "import geopandas as gpd\n",
    "\n",
    "# Machine learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Other utilities\n",
    "import itertools\n",
    "import joblib\n",
    "\n",
    "# Custom modules - Add paths\n",
    "functions_path = Path(\"/home/mokr/Loss_Functions_Paper/ML_Functions/\")\n",
    "sys.path.append(str(functions_path))\n",
    "\n",
    "# Custom module imports\n",
    "import ML_functions\n",
    "from ML_functions import (\n",
    "    HydroDataset,\n",
    "    transform_CMAL_parameters_multi,\n",
    "    run_ensemble_predictions,\n",
    "    replace_keys, load_and_unnormalize\n",
    ")\n",
    "\n",
    "from ML_Plots import *\n",
    "from ML_Losses import compute_log_likelihood, compute_CDF, crps_loss,  get_member_summaries_torch,\n",
    "from ML_Processing import process_ensemble_predictions\n",
    "from ML_Metrics import calculate_nse, calculate_kge, compute_crps, compute_crps_np, calculate_overall_crps, calculate_model_crps, count_zero_variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7414843-7a88-445f-8f66-a1e0a893bce5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adeee6-72f5-4db7-8f94-8a81ef9aa42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the directory where your files are saved\n",
    "data_dir = \"/home/mokr/Loss_Functions_Paper/forecast_results/\"\n",
    "\n",
    "\n",
    "# Define the variable names\n",
    "variable_names = [\n",
    "    \"ensemble_summaries\",\n",
    "    \"crps_per_leadtime\",\n",
    "    \"stored_forecasts\",\n",
    "    # \"KGE_scores\",\n",
    "    # \"NSE_scores\",\n",
    "    # \"basin_forecasts\",\n",
    "    \"variogram_scores\",\n",
    "    \"metadata\",\n",
    "\n",
    "]\n",
    "\n",
    "# Load each file into its corresponding variable\n",
    "loaded_data = {}\n",
    "for name in variable_names:\n",
    "    with open(os.path.join(data_dir, f\"{name}_Part0_all_test.pkl\"), \"rb\") as f:\n",
    "        loaded_data[name] = pickle.load(f)\n",
    "\n",
    "ensemble_summaries = loaded_data[\"ensemble_summaries\"]\n",
    "crps_per_leadtime = loaded_data[\"crps_per_leadtime\"]\n",
    "stored_forecasts = loaded_data[\"stored_forecasts\"]\n",
    "# KGE_scores = loaded_data[\"KGE_scores\"]\n",
    "# NSE_scores = loaded_data[\"NSE_scores\"]\n",
    "# basin_forecasts = loaded_data[\"basin_forecasts\"]\n",
    "metadata = loaded_data[\"metadata\"]\n",
    "variogram_scores = loaded_data[\"variogram_scores\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1667b49-d3d4-4da6-8648-64fa6dd40f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_map = {\n",
    "    \"CRPS\": \"Conditional\",\n",
    "    \"NonBinary\": \"Probabilistic\",\n",
    "    \"Fixed_Seeded\": \"Seeded (Static)\",\n",
    "    \"Non_Fixed_Seeded\": \"Seeded (Variable)\"\n",
    "}\n",
    "\n",
    "\n",
    "# Apply to your dictionaries\n",
    "ensemble_summaries = replace_keys(ensemble_summaries, key_map)\n",
    "crps_per_leadtime = replace_keys(crps_per_leadtime, key_map)\n",
    "stored_forecasts = replace_keys(stored_forecasts, key_map)\n",
    "variogram_scores = replace_keys(variogram_scores, key_map)\n",
    "\n",
    "models = ['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic']\n",
    "colors = ['#2E86AB', '#F18F01', '#06A77D', '#A23B72']\n",
    "model_colors = dict(zip(models, colors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b38e5-8a85-4700-81f7-af88c7d067c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract Basin IDs from Metadata\n",
    "# Since metadata is a structured array with fields, we can access 'basin_idx' directly.\n",
    "# This avoids a slow Python loop.\n",
    "basin_ids = metadata['basin_idx']\n",
    "\n",
    "# Initialize a dictionary to hold the DataFrames for each model\n",
    "catchment_crps_dfs = {}\n",
    "\n",
    "for model in models:    \n",
    "    # crps_per_leadtime[model] shape: (695505, 10)\n",
    "    df = pd.DataFrame(\n",
    "        crps_per_leadtime[model], \n",
    "        columns=[f'Lead_{t}' for t in range(10)]\n",
    "    )\n",
    "    \n",
    "    # Add the Basin ID column\n",
    "    df['Basin'] = basin_ids\n",
    "    \n",
    "    # 3. Group by Basin and Calculate Mean\n",
    "    # This results in a DataFrame where Index = Basin ID, Columns = Lead Times\n",
    "    average_per_catchment = df.groupby('Basin').mean()\n",
    "    \n",
    "    catchment_crps_dfs[model] = average_per_catchment\n",
    "\n",
    "# --- Example Usage ---\n",
    "# View the first few rows for the 'Conditional' model\n",
    "print(\"\\nAverage CRPS per Catchment (Conditional Model):\")\n",
    "print(catchment_crps_dfs['Conditional'].head())\n",
    "\n",
    "catchment_crps_dfs['Conditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e31d85-4dd3-4e42-ad8e-97cb21f403c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each model\n",
    "leadtimes = np.arange(3, 11)\n",
    "print(f\"Lead times: {leadtimes}\")\n",
    "Tick_Size = 16\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "models = ['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic']\n",
    "colors = ['#2E86AB', '#F18F01', '#06A77D', '#A23B72']\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "confidence_level = 0.95  # 95% confidence interval\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "\n",
    "    data = crps_per_leadtime[model]  # shape: (n_samples, 10)\n",
    "    # Calculate mean across samples (axis=0), ignoring NaNs\n",
    "    mean_vals = np.nanmean(data, axis=0)[2:]\n",
    "    \n",
    "    # Calculate confidence intervals for each leadtime\n",
    "    ci_lower = np.zeros(len(leadtimes))\n",
    "    ci_upper = np.zeros(len(leadtimes))\n",
    "    \n",
    "    for i in range(len(leadtimes)):\n",
    "        # Get data for this leadtime, removing NaNs\n",
    "        leadtime_data = data[:, i]\n",
    "        leadtime_data = leadtime_data[~np.isnan(leadtime_data)]\n",
    "        \n",
    "        if len(leadtime_data) > 1:\n",
    "            # Calculate standard error\n",
    "            sem = stats.sem(leadtime_data)\n",
    "            n = len(leadtime_data)\n",
    "            \n",
    "            # Get t-critical value\n",
    "            t_critical = stats.t.ppf(1 - (1-confidence_level)/2, df=n-1)\n",
    "            \n",
    "            # Calculate margin of error\n",
    "            margin = t_critical * sem\n",
    "            \n",
    "            ci_lower[i] = mean_vals[i] - margin\n",
    "            ci_upper[i] = mean_vals[i] + margin\n",
    "\n",
    "        else:\n",
    "            # Not enough data for CI\n",
    "            ci_lower[i] = mean_vals[i]\n",
    "            ci_upper[i] = mean_vals[i]\n",
    "            print(f\"    WARNING: Not enough data for CI (n={len(leadtime_data)})\")\n",
    "\n",
    "    \n",
    "    # Plot confidence interval as shaded region\n",
    "    ax.fill_between(leadtimes, ci_lower, ci_upper, \n",
    "                     color=colors[idx], alpha=0.2)\n",
    "    \n",
    "    # Plot mean line\n",
    "    ax.plot(leadtimes, mean_vals, \n",
    "            color=colors[idx], \n",
    "            linestyle=linestyles[idx],\n",
    "            linewidth=2.5, \n",
    "            label=model,\n",
    "            marker='o',\n",
    "            markersize=6)\n",
    "    \n",
    "    print(f\"✓ Successfully plotted {model}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Setting up plot formatting...\")\n",
    "ax.set_xlabel('Lead Time', fontsize=18, fontweight='bold')\n",
    "ax.set_ylabel('CRPS', fontsize=18, fontweight='bold')\n",
    "ax.set_title('CRPS by Lead Time (with 95% Confidence Intervals)', \n",
    "             fontsize=22, fontweight='bold', pad=20)\n",
    "ax.legend(loc='best', fontsize=16, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.tick_params(axis='both', which='major', labelsize=Tick_Size)\n",
    "ax.set_xticks(leadtimes)\n",
    "plt.tight_layout()\n",
    "print(\"Displaying plot...\")\n",
    "plt.show()\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7f3c9-db3e-4105-b048-4f6c82ac4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "num_leadtimes = 10\n",
    "num_members = 11\n",
    "num_bins = num_members + 1  # 12 bins for 11 members\n",
    "\n",
    "# Create figure with subplots for each leadtime\n",
    "fig = plt.figure(figsize=(25, 12))\n",
    "fig.suptitle('Rank Histograms by Lead Time', fontsize=28, fontweight='bold', y=0.98)\n",
    "\n",
    "# Create 2x5 grid for 10 leadtimes\n",
    "axes = fig.subplots(2, 5)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Global legend storage\n",
    "global_handles = []\n",
    "global_labels = []\n",
    "\n",
    "# Process each leadtime\n",
    "for leadtime_idx in range(num_leadtimes):\n",
    "    ax = axes[leadtime_idx]\n",
    "    \n",
    "    # Calculate ranks for each model at this leadtime\n",
    "    model_rank_distributions = {}\n",
    "    \n",
    "    for model in models:\n",
    "        # Get forecasts and truth for this leadtime\n",
    "        forecasts = stored_forecasts[model][:, :, leadtime_idx]  # (n_samples, n_members)\n",
    "        truth = stored_forecasts['Discharge'][:, 0, leadtime_idx]  # (n_samples,)\n",
    "        \n",
    "        # Remove any NaN samples\n",
    "        valid_mask = ~(np.isnan(forecasts).any(axis=1) | np.isnan(truth))\n",
    "        forecasts = forecasts[valid_mask]\n",
    "        truth = truth[valid_mask]\n",
    "        \n",
    "        # Calculate ranks: count how many ensemble members are below the observation\n",
    "        # ranks[i] = number of ensemble members < truth[i]\n",
    "        ranks = np.sum(forecasts < truth[:, np.newaxis], axis=1)\n",
    "        \n",
    "        # Create histogram (bins 0, 1, 2, ..., 11)\n",
    "        hist, _ = np.histogram(ranks, bins=np.arange(num_bins + 1), density=True)\n",
    "        \n",
    "        model_rank_distributions[model] = hist\n",
    "    \n",
    "    # Plot bars for each model\n",
    "    num_models = len(models)\n",
    "    x = np.arange(num_bins)\n",
    "    width = 0.8 / num_models\n",
    "    \n",
    "    for j, model in enumerate(models):\n",
    "        hist = model_rank_distributions[model]\n",
    "        \n",
    "        bar = ax.bar(\n",
    "            x + j * width,\n",
    "            hist,\n",
    "            width=width,\n",
    "            label= model,\n",
    "            color=colors[j],\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "        # Store handles/labels only from first subplot\n",
    "        if leadtime_idx == 0:\n",
    "            global_handles.append(bar)\n",
    "            global_labels.append(model)\n",
    "    \n",
    "    # Add uniform distribution reference line\n",
    "    ideal_probability = 1.0 / num_bins\n",
    "    uniform_line = ax.axhline(y=ideal_probability, color='red', linestyle='--', \n",
    "                              linewidth=2, alpha=0.7, zorder=10, label='Uniform')\n",
    "    \n",
    "    # Add uniform line to legend (only once)\n",
    "    if leadtime_idx == 0:\n",
    "        global_handles.append(uniform_line)\n",
    "        global_labels.append('Uniform')\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_title(f\"Lead Time {leadtime_idx + 1}\", fontsize=18, fontweight='bold', pad=10)\n",
    "    ax.set_xlabel(\"Ensemble Members Below Observation\", fontsize=14, labelpad=5)\n",
    "    ax.set_ylabel(\"Probability\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x + width * (num_models - 1) / 2)\n",
    "    ax.set_xticklabels(range(num_bins), fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.set_ylim(0, 0.35)  # Adjust based on your data\n",
    "    \n",
    "    # Disable individual legends\n",
    "    if ax.get_legend():\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "# Create single legend at the top\n",
    "fig.legend(handles=global_handles, labels=global_labels,\n",
    "           loc='upper center', bbox_to_anchor=(0.5, 0.95),\n",
    "           ncol=len(global_labels), fontsize=16, frameon=False,\n",
    "           fancybox=False, shadow=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85, hspace=0.3, wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f77b3e-85e1-4d09-8222-c3d9737a0db3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Diagnosing Spread Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be146ce-be9b-430b-9350-d452fcf55117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define CRPS intervals\n",
    "intervals = [(0, 0.1), (0.1, 1), (1, 10), (10, np.inf)]\n",
    "interval_labels = ['0-0.1', '0.1-1', '1-10', '10+']\n",
    "\n",
    "print(\"CRPS Distribution Across Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    data = crps_per_leadtime[model]  # shape: (n_samples, 10)\n",
    "    \n",
    "    # Flatten to get all CRPS values for this model\n",
    "    all_crps = data.flatten()\n",
    "    \n",
    "    # Remove NaNs\n",
    "    all_crps = all_crps[~np.isnan(all_crps)]\n",
    "    \n",
    "    total_count = len(all_crps)\n",
    "    \n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  Total predictions: {total_count}\")\n",
    "    \n",
    "    # Count how many fall in each interval\n",
    "    counts = []\n",
    "    percentages = []\n",
    "    \n",
    "    for (lower, upper), label in zip(intervals, interval_labels):\n",
    "        if upper == np.inf:\n",
    "            count = np.sum(all_crps >= lower)\n",
    "        else:\n",
    "            count = np.sum((all_crps >= lower) & (all_crps < upper))\n",
    "        \n",
    "        pct = (count / total_count * 100) if total_count > 0 else 0\n",
    "        counts.append(count)\n",
    "        percentages.append(pct)\n",
    "        \n",
    "        print(f\"  {label:>10}: {count:6d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    results[model] = {\n",
    "        'counts': counts,\n",
    "        'percentages': percentages,\n",
    "        'total': total_count\n",
    "    }\n",
    "\n",
    "# Create a nice summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nSUMMARY TABLE (Counts)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create DataFrame for counts\n",
    "count_data = {model: results[model]['counts'] for model in models}\n",
    "count_df = pd.DataFrame(count_data, index=interval_labels)\n",
    "print(count_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"\\nSUMMARY TABLE (Percentages)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create DataFrame for percentages\n",
    "pct_data = {model: [f\"{p:.1f}%\" for p in results[model]['percentages']] for model in models}\n",
    "pct_df = pd.DataFrame(pct_data, index=interval_labels)\n",
    "print(pct_df.to_string())\n",
    "# Additional analysis: mean CRPS per interval\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nMEAN CRPS WITHIN EACH INTERVAL (per model)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for model in models:\n",
    "    data = crps_per_leadtime[model]\n",
    "    all_crps = data.flatten()\n",
    "    all_crps = all_crps[~np.isnan(all_crps)]\n",
    "    \n",
    "    # Calculate overall mean CRPS for this model\n",
    "    overall_mean = np.mean(all_crps)\n",
    "    total_count = len(all_crps)\n",
    "    \n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  Overall mean CRPS: {overall_mean:.2f}\")\n",
    "    print(f\"  Total predictions: {total_count}\")\n",
    "    print(f\"  {'Interval':>10} | {'Mean':>8} | {'Count':>6} | {'% of total':>10} | {'Contribution':>12}\")\n",
    "    print(f\"  {'-'*10}-+-{'-'*8}-+-{'-'*6}-+-{'-'*10}-+-{'-'*12}\")\n",
    "    \n",
    "    total_contribution = 0\n",
    "    \n",
    "    for (lower, upper), label in zip(intervals, interval_labels):\n",
    "        if upper == np.inf:\n",
    "            interval_data = all_crps[all_crps >= lower]\n",
    "        else:\n",
    "            interval_data = all_crps[(all_crps >= lower) & (all_crps < upper)]\n",
    "        \n",
    "        if len(interval_data) > 0:\n",
    "            mean_crps = np.mean(interval_data)\n",
    "            count = len(interval_data)\n",
    "            percentage = (count / total_count) * 100\n",
    "            \n",
    "            # Calculate contribution to overall mean\n",
    "            # Contribution = (count / total_count) * mean_of_interval\n",
    "            contribution = (count / total_count) * mean_crps\n",
    "            total_contribution += contribution\n",
    "            \n",
    "            print(f\"  {label:>10} | {mean_crps:8.2f} | {count:6d} | {percentage:9.1f}% | {contribution:12.2f}\")\n",
    "        else:\n",
    "            print(f\"  {label:>10} | {'no data':>8} | {0:6d} | {0:9.1f}% | {0:12.2f}\")\n",
    "    \n",
    "    print(f\"  {'-'*10}-+-{'-'*8}-+-{'-'*6}-+-{'-'*10}-+-{'-'*12}\")\n",
    "    print(f\"  {'TOTAL':>10} | {overall_mean:8.2f} | {total_count:6d} | {100.0:9.1f}% | {total_contribution:12.2f}\")\n",
    "    \n",
    "    # Verification check\n",
    "    if abs(total_contribution - overall_mean) > 0.01:\n",
    "        print(f\"  WARNING: Contribution sum ({total_contribution:.2f}) doesn't match overall mean ({overall_mean:.2f})\")\n",
    "\n",
    "\n",
    "# Check if best model is really better at high-error cases\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nHYPOTHESIS CHECK: Does your best model perform relatively better at high errors?\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for (lower, upper), label in zip(intervals, interval_labels):\n",
    "    print(f\"\\n{label} interval:\")\n",
    "    \n",
    "    interval_means = {}\n",
    "    interval_contributions = {}\n",
    "    \n",
    "    for model in models:\n",
    "        data = crps_per_leadtime[model]\n",
    "        all_crps = data.flatten()\n",
    "        all_crps = all_crps[~np.isnan(all_crps)]\n",
    "        total_count = len(all_crps)\n",
    "        \n",
    "        if upper == np.inf:\n",
    "            interval_data = all_crps[all_crps >= lower]\n",
    "        else:\n",
    "            interval_data = all_crps[(all_crps >= lower) & (all_crps < upper)]\n",
    "        \n",
    "        if len(interval_data) > 0:\n",
    "            interval_means[model] = np.mean(interval_data)\n",
    "            interval_contributions[model] = (len(interval_data) / total_count) * interval_means[model]\n",
    "        else:\n",
    "            interval_means[model] = np.nan\n",
    "            interval_contributions[model] = 0\n",
    "    \n",
    "    # Sort models by performance in this interval\n",
    "    sorted_models = sorted(interval_means.items(), key=lambda x: x[1] if not np.isnan(x[1]) else np.inf)\n",
    "    \n",
    "    for rank, (model, mean_val) in enumerate(sorted_models, 1):\n",
    "        if not np.isnan(mean_val):\n",
    "            contrib = interval_contributions[model]\n",
    "            print(f\"  {rank}. {model:25s}: mean = {mean_val:8.2f}, contribution = {contrib:8.2f}\")\n",
    "\n",
    "# Summary: Which interval contributes most to each model's overall CRPS?\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nWHICH INTERVAL CONTRIBUTES MOST TO OVERALL CRPS?\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for model in models:\n",
    "    data = crps_per_leadtime[model]\n",
    "    all_crps = data.flatten()\n",
    "    all_crps = all_crps[~np.isnan(all_crps)]\n",
    "    total_count = len(all_crps)\n",
    "    \n",
    "    contributions = []\n",
    "    \n",
    "    for (lower, upper), label in zip(intervals, interval_labels):\n",
    "        if upper == np.inf:\n",
    "            interval_data = all_crps[all_crps >= lower]\n",
    "        else:\n",
    "            interval_data = all_crps[(all_crps >= lower) & (all_crps < upper)]\n",
    "        \n",
    "        if len(interval_data) > 0:\n",
    "            mean_crps = np.mean(interval_data)\n",
    "            contribution = (len(interval_data) / total_count) * mean_crps\n",
    "            contributions.append((label, contribution))\n",
    "        else:\n",
    "            contributions.append((label, 0))\n",
    "    \n",
    "    # Sort by contribution\n",
    "    contributions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n{model}:\")\n",
    "    for rank, (label, contrib) in enumerate(contributions, 1):\n",
    "        pct_of_total = (contrib / np.mean(all_crps)) * 100 if np.mean(all_crps) > 0 else 0\n",
    "        print(f\"  {rank}. {label:>10}: {contrib:8.2f} ({pct_of_total:5.1f}% of total CRPS)\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e42b29-7a8e-49a5-8e8e-1458d9d579c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Making CDF Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37940c91-4bfe-4a20-9692-0ff04c74e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract catchment IDs from metadata\n",
    "catchments = np.array(metadata['basin_idx'])  # Keep as string array\n",
    "\n",
    "# Find boundaries where catchment changes\n",
    "change_points = np.where(catchments[:-1] != catchments[1:])[0] + 1\n",
    "boundaries = np.concatenate([[0], change_points, [len(catchments)]])\n",
    "\n",
    "# Get unique catchments in order of appearance\n",
    "unique_catchments = [catchments[boundaries[i]] for i in range(len(boundaries) - 1)]\n",
    "\n",
    "# Models to process\n",
    "\n",
    "\n",
    "# Create results more efficiently\n",
    "results = []\n",
    "\n",
    "for model in models:\n",
    "    data = crps_per_leadtime[model]  # shape: (200000, 10)\n",
    "    \n",
    "    for catchment_idx, catchment in enumerate(unique_catchments):\n",
    "        start = boundaries[catchment_idx]\n",
    "        end = boundaries[catchment_idx + 1]\n",
    "        \n",
    "        # Extract all leadtimes for this catchment at once\n",
    "        catchment_data = data[start:end, :]  # shape: (n_samples, 10)\n",
    "        \n",
    "        # Calculate mean for all leadtimes at once\n",
    "        mean_crps = np.nanmean(catchment_data, axis=0)\n",
    "        counts = np.sum(~np.isnan(catchment_data), axis=0)\n",
    "        \n",
    "        # Add results for all leadtimes\n",
    "        for leadtime in range(1, 11):\n",
    "            results.append({\n",
    "                'model': model,\n",
    "                'catchment': catchment,\n",
    "                'leadtime': leadtime,\n",
    "                'mean_crps': mean_crps[leadtime - 1],\n",
    "                'n_samples': counts[leadtime - 1]\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "df_catchment = pd.DataFrame(results)\n",
    "\n",
    "# Pivot to get leadtimes as columns\n",
    "df_pivot = df_catchment.pivot_table(\n",
    "    index=['model', 'catchment'],\n",
    "    columns='leadtime',\n",
    "    values='mean_crps'\n",
    ")\n",
    "df_pivot.columns = [f'leadtime_{i}' for i in df_pivot.columns]\n",
    "df_pivot = df_pivot.reset_index()\n",
    "\n",
    "print(\"Long format DataFrame shape:\", df_catchment.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013b4b9-5576-4dd9-bc7c-b6a8a848144f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Models to plot\n",
    "\n",
    "leadtimes = np.arange(1, 11)\n",
    "Title_Size = 28\n",
    "# Create subplots - one for each leadtime\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = ['#2E86AB', '#F18F01', '#06A77D', '#A23B72']\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "linewidth = 2.5\n",
    "\n",
    "for lt_idx, ax in enumerate(axes):\n",
    "    leadtimes = [3, 10]\n",
    "    leadtime = leadtimes[lt_idx]\n",
    "    \n",
    "    for model_idx, model in enumerate(models):\n",
    "        # Get catchment-averaged CRPS for this model and leadtime\n",
    "        model_data = df_pivot[df_pivot['model'] == model]\n",
    "        col = f'leadtime_{leadtime}'\n",
    "        data = model_data[col].dropna().values\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            # Sort data for CDF\n",
    "            sorted_data = np.sort(data)\n",
    "            # Calculate cumulative probabilities\n",
    "            cum_prob = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "            \n",
    "            ax.plot(sorted_data, cum_prob,\n",
    "                   color=colors[model_idx],\n",
    "                   linestyle=linestyles[model_idx],\n",
    "                   linewidth=linewidth,\n",
    "                   alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('CRPS (Catchment Average)', fontsize=Title_Size, fontweight='bold')\n",
    "    ax.set_ylabel('Cumulative Probability', fontsize=Title_Size, fontweight='bold')\n",
    "    ax.set_title(f'Lead Time {leadtime}', fontsize=Title_Size, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "    # Make tick labels bigger\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    # ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "\n",
    "# Create custom legend elements\n",
    "legend_elements = [Line2D([0], [0], color=colors[i], linestyle=linestyles[i], \n",
    "                          linewidth=linewidth, label=models[i]) \n",
    "                   for i in range(len(models))]\n",
    "\n",
    "# Add legend at the top of the figure\n",
    "fig.legend(handles=legend_elements, loc='upper center', ncol=4, \n",
    "          frameon=False, fontsize=30, bbox_to_anchor=(0.5, 0.984))\n",
    "\n",
    "plt.suptitle('Cumulative Distribution Functions of Catchment-Averaged CRPS by Lead Time', \n",
    "             fontsize=36, fontweight='bold', y=0.998)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])  # Leave space at top for legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d26e8-c2e0-4eb1-9edd-7e3c83d0fc2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Getting hydrographs over 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97816424-7f6a-4912-bd19-abef01fc6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_path = '/home/mokr/Loss_Functions_Paper/Scalers/discharge_caravan_scalers.joblib'\n",
    "scalers = joblib.load(scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea1419-2b7a-4b78-8d8a-b282e9299e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract basin IDs and dates from metadata\n",
    "basin_ids = np.array([meta[1] for meta in metadata])\n",
    "dates = np.array([datetime.strptime(meta[0], '%Y-%m-%d %H:%M:%S') for meta in metadata])\n",
    "\n",
    "# Get unique basins while preserving order\n",
    "unique_basins = []\n",
    "seen = set()\n",
    "for basin in basin_ids:\n",
    "    if basin not in seen:\n",
    "        unique_basins.append(basin)\n",
    "        seen.add(basin)\n",
    "\n",
    "# Split forecasts by model and basin\n",
    "forecasts_by_model_and_basin = {}\n",
    "for model in models:\n",
    "    forecasts_by_model_and_basin[model] = {}\n",
    "    for basin in unique_basins:\n",
    "        mask = basin_ids == basin\n",
    "        forecasts_by_model_and_basin[model][basin] = stored_forecasts[model][mask]\n",
    "\n",
    "# Split truth by basin\n",
    "truth_by_basin = {}\n",
    "for basin in unique_basins:\n",
    "    mask = basin_ids == basin\n",
    "    truth_by_basin[basin] = stored_forecasts['Discharge'][mask][:, 0, :]\n",
    "\n",
    "\n",
    "average_crps_by_basin = {}\n",
    "for model in models:\n",
    "    average_crps_by_basin[model] = {}\n",
    "    for basin in unique_basins:\n",
    "        mask = basin_ids == basin\n",
    "        average_crps_by_basin[model][basin] = np.mean(crps_per_leadtime[model][mask])\n",
    "\n",
    "\n",
    "# Split metadata and dates by basin\n",
    "metadata_by_basin = {}\n",
    "dates_by_basin = {}\n",
    "for basin in unique_basins:\n",
    "    mask = basin_ids == basin\n",
    "    metadata_by_basin[basin] = metadata[mask]\n",
    "    dates_by_basin[basin] = dates[mask]\n",
    "\n",
    "average_crps_by_basin = {}\n",
    "for model in models:\n",
    "    average_crps_by_basin[model] = {}\n",
    "    for basin in unique_basins:\n",
    "        mask = basin_ids == basin\n",
    "        average_crps_by_basin[model][basin] = np.mean(crps_per_leadtime[model][mask], axis = 1)\n",
    "    \n",
    "print(f\"Scaled example: {forecasts_by_model_and_basin[models[0]][unique_basins[0]][0, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee49fab-d850-4243-a4d7-82a5ca800982",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_by_basin['camelscl_5707002'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b024a71-9763-4ff8-a3f2-79cc3d3216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or fix the basin and randomize sample index\n",
    "plots = generate_random_plots(\n",
    "    forecasts_by_model_and_basin, \n",
    "    truth_by_basin,\n",
    "    metadata_by_basin,\n",
    "    models=models,\n",
    "    colors=colors,\n",
    "    n_plots=1,\n",
    "    basin_idx = 'hysets_0422026250',\n",
    "    sample_idx = 727,\n",
    "    average_crps_by_basin=average_crps_by_basin\n",
    ")\n",
    "# Plot 1: Basin = hysets_01589290, Sample = 40\n",
    "# Plot 6: Basin = hysets_0422026250, Sample = 727\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ad882-5f4d-4537-9c0d-a3489d76be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_per_leadtime['Conditional'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e119f8-4255-4f2a-926c-ce145850b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 2x2 grid\n",
    "basins = ['hysets_11042631', 'camelscl_5707002']\n",
    "leadtimes = [2, 9]  # Leadtime 3 (index 2) and Leadtime 10 (index 9)\n",
    "\n",
    "plot_hydrograph_grid(\n",
    "    forecasts_by_model_and_basin, \n",
    "    truth_by_basin,\n",
    "    dates_by_basin,\n",
    "    basins, \n",
    "    'Conditional', \n",
    "    leadtimes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b69811-9491-406d-8be6-2d26b1e5fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin = 'hysets_06177500' # Flashy arid hysets_08330600, hysets_11042631\n",
    "\n",
    "plot_hydrograph(\n",
    "    forecasts_by_model_and_basin,\n",
    "    truth_by_basin,\n",
    "    dates_by_basin,\n",
    "    basin='hysets_07311900',\n",
    "    model='Conditional',\n",
    "    leadtime_idx=2\n",
    ")\n",
    "\n",
    " # camelscl_5707002 Probabilistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7535df-c589-4283-bc89-807fdcfa49e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Recording the overal scores of each model\n",
    "\n",
    "- NSE. KGE, Autoregression prediction etc. scores for random ensemble members\n",
    "- CRPS scores for each leadtime\n",
    "- CRPS scores of how well it predicts Autoregression, Mean Flow, Variance of Flow etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76e325-8440-48d1-9e87-4338505c5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crps = calculate_model_crps(\n",
    "    ensemble_summaries, \n",
    "    model_names=['Conditional'],\n",
    "    metrics=['total_flow', 'variance', 'autoregression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7471825-56f1-4d61-9b37-68c656816e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb33bd-9904-4f2e-a78f-6507818697de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CRPS with confidence intervals\n",
    "model_names = ['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic']\n",
    "metrics = ['total_flow', 'variance', 'autoregression', 'gamma', 'num_rise']\n",
    "\n",
    "model_crps_mean, model_crps_ci = calculate_crps_with_ci(\n",
    "    ensemble_summaries, model_names, metrics, confidence=0.95\n",
    ")\n",
    "\n",
    "# Create comparison DataFrame with confidence intervals\n",
    "comparison_data = {'CRPS Metric': ['Total Flow', 'Variance', 'Autoregression', 'Gamma', 'Num Rise']}\n",
    "\n",
    "# Add each model's results with ± CI\n",
    "for model_name in model_names:\n",
    "    if model_name in model_crps_mean:\n",
    "        comparison_data[model_name] = [\n",
    "            f\"{model_crps_mean[model_name][metric]:.3g} ± {model_crps_ci[model_name][metric]:.3g}\"\n",
    "            for metric in metrics\n",
    "        ]\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "comparison_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a34136-bf94-4ba4-86e0-6913c930372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b27a95-38fb-4ba7-a255-47ec8a5c8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic']\n",
    "metrics = ['total_flow', 'variance', 'autoregression', 'gamma', 'num_rise']\n",
    "\n",
    "# Calculate all CRPS values at once\n",
    "model_crps = calculate_model_crps(ensemble_summaries, model_names, metrics)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = {'CRPS Metric': ['Total Flow', 'Variance', 'Autoregression',  'Gamma', 'Num Rise']}\n",
    "\n",
    "# Add each model's results with custom display names\n",
    "for i, model_name in enumerate(model_names):\n",
    "    if model_name in model_crps:\n",
    "        comparison_data[model_name] = [\n",
    "            float(f\"{model_crps[model_name][metric]:.3g}\") for metric in metrics\n",
    "        ]\n",
    "# Create DataFrame and set precision\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# Display transposed version\n",
    "comparison_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d23a06-fb9e-456f-9601-152a60fa1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crps_per_example = calculate_model_crps(\n",
    "    ensemble_summaries, \n",
    "    model_names=['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic'],  # Add your model names\n",
    "    metrics=['total_flow', 'autoregression', 'gamma', 'num_rise'],  \n",
    "    return_mean=False\n",
    ")\n",
    "\n",
    "\n",
    "flow_crps_df = create_metric_crps_df('total_flow', model_names, model_names, model_crps_per_example)\n",
    "autoregression_crps_df = create_metric_crps_df('autoregression', model_names, model_names, model_crps_per_example)\n",
    "gamma_crps_df = create_metric_crps_df('gamma', model_names, model_names, model_crps_per_example)\n",
    "num_rise_crps_df = create_metric_crps_df('num_rise', model_names, model_names, model_crps_per_example)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(flow_crps_df.shape)  # Should be (695505, n_models)\n",
    "flow_crps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a999d7-9eda-47f1-897f-718e4afc648e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Plotting Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc49d0f-2c25-4d0f-bc7b-ee5ac1da3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 11\n",
    "dispersion_df = get_dispersion_calculations(ensemble_summaries, ensemble_summaries['Discharge'])\n",
    "\n",
    "metrics = ['total_flow', 'autoregression', 'gamma', 'num_rise']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebdf7c-872e-4eca-aac5-04a3ade84c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_df = dispersion_df.drop(columns=[col for col in dispersion_df.columns if 'Discharge' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1e22b-3ec0-419e-ac19-eaab55718c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 15))\n",
    "fig.suptitle('Rank Histograms of Temporal Characteristics', fontsize=28, fontweight='bold', y=0.93)\n",
    "\n",
    "# Create subplots\n",
    "axes = fig.subplots(2, 2)\n",
    "axes = axes.flatten()\n",
    "models = ['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic']\n",
    "colors = ['#2E86AB', '#F18F01', '#06A77D', '#A23B72']\n",
    "\n",
    "# Lists to store handles and labels for the global legend\n",
    "global_handles = []\n",
    "global_labels = []\n",
    "Tick_Size = 20\n",
    "Axis_Size = 22\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Extract data for current metric\n",
    "    metric_columns = [col for col in dispersion_df.columns if metric in col]\n",
    "    \n",
    "    model_names = []\n",
    "    metric_values = []\n",
    "    \n",
    "    for col in metric_columns:\n",
    "        # Extract model name\n",
    "        model_name = col.replace(f'_{metric}', '')\n",
    "        \n",
    "        display_name = model_name_mapping.get(model_name, model_name) if 'model_name_mapping' in locals() else model_name\n",
    "            \n",
    "        model_names.append(display_name)\n",
    "        metric_values.append(dispersion_df[col].values / 100) \n",
    "    \n",
    "    # Rank bins\n",
    "    rank_bins = dispersion_df.index.tolist()\n",
    "    \n",
    "    # Bar plot setup\n",
    "    num_models = len(model_names)\n",
    "    x = np.arange(len(rank_bins)) \n",
    "    width = 0.8 / num_models \n",
    "    \n",
    "    for j, values in enumerate(metric_values):\n",
    "        # --- FIX 2: Capture the bar object for the legend ---\n",
    "        bar = ax.bar(\n",
    "            x + j * width, \n",
    "            values, \n",
    "            width=width, \n",
    "            label=model_names[j], # Label is assigned here\n",
    "            color=colors[j % len(colors)],\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        # Store handles/labels ONLY from the first subplot to avoid duplicates\n",
    "        if i == 0:\n",
    "            global_handles.append(bar)\n",
    "            global_labels.append(model_names[j])\n",
    "    \n",
    "    # --- FIX 3: Add Red Line to Legend as 'Uniform' ---\n",
    "    ideal_probability = 1.0 / len(rank_bins)\n",
    "    uniform_line = ax.axhline(y=ideal_probability, color='red', linestyle='--', linewidth=2, \n",
    "               alpha=0.7, zorder=10, label='Uniform')\n",
    "    \n",
    "    # Add the Uniform line to the global legend lists (only once)\n",
    "    if i == 0:\n",
    "        global_handles.append(uniform_line)\n",
    "        global_labels.append('Uniform')\n",
    "\n",
    "    # Improved formatting\n",
    "    metric_title = metric.replace('_', ' ').title()\n",
    "    ax.set_title(f\"{metric_title}\", fontsize=22, fontweight='bold', pad=10)\n",
    "    ax.set_xlabel(\"Ensemble Members Below Observation\", fontsize=Axis_Size, labelpad=1)\n",
    "    ax.set_ylabel(\"Probability\", fontsize=Axis_Size, fontweight='bold')\n",
    "    ax.set_xticks(x + width * (num_models - 1) / 2)\n",
    "    ax.set_xticklabels(rank_bins, fontsize=Tick_Size)\n",
    "    ax.tick_params(axis='y', labelsize=Tick_Size)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Disable individual subplot legends\n",
    "    if ax.get_legend():\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylim(0, 0.6)\n",
    "\n",
    "# Create single legend at the top using the collected HANDLES\n",
    "# Note: ncol includes len(models) + 1 for the Uniform line\n",
    "fig.legend(handles=global_handles, labels=global_labels, \n",
    "           loc='upper center', bbox_to_anchor=(0.5, 0.9), \n",
    "           ncol=len(global_labels), fontsize=20, frameon=False, \n",
    "           fancybox=False, shadow=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.82, hspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a8bce-d83c-477a-a73c-0c68fcc20992",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_crps = calculate_model_crps(\n",
    "    ensemble_summaries, \n",
    "    model_names=['Conditional'],\n",
    "    metrics=['total_flow', 'variance', 'autoregression'])\n",
    "\n",
    "model_crps_per_example = calculate_model_crps(\n",
    "    ensemble_summaries, \n",
    "    model_names=['Conditional', 'Seeded (Static)', 'Seeded (Variable)', 'Probabilistic'],  # Add your model names\n",
    "    metrics=['total_flow', 'autoregression', 'gamma', 'num_rise'],  \n",
    "    return_mean=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bddd2-6baa-4ecc-9a83-e95ca0ae4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['basin_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc2aee-7d50-4926-80c1-0bdc73a4c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "flow_crps_df = create_metric_crps_df('total_flow', model_names, model_names, model_crps_per_example)\n",
    "autoregression_crps_df = create_metric_crps_df('autoregression', model_names, model_names, model_crps_per_example)\n",
    "gamma_crps_df = create_metric_crps_df('gamma', model_names, model_names, model_crps_per_example)\n",
    "num_rise_crps_df = create_metric_crps_df('num_rise', model_names, model_names, model_crps_per_example)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(flow_crps_df.shape)  # Should be (695505, n_models)\n",
    "flow_crps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d218334-0df2-443c-bde5-c6cec8f60e7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Making CRPS Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41b657-da91-4799-b45b-b83495b4dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add the basins array as a column\n",
    "basins = metadata['basin_idx']\n",
    "flow_crps_df['Basin'] = basins\n",
    "autoregression_crps_df['Basin'] = basins\n",
    "gamma_crps_df['Basin'] = basins\n",
    "num_rise_crps_df['Basin'] = basins\n",
    "\n",
    "# 2. Group by Basin and calculate the mean over the arrays in each cell\n",
    "# np.stack turns the list of arrays into a matrix, axis=0 averages across the rows (forecasts)\n",
    "# 1. Group by Basin and average the arrays (as established before)\n",
    "flow_crps_df['Basin'] = basins\n",
    "grouped = flow_crps_df.groupby('Basin', as_index=False).agg(lambda x: np.mean(np.stack(x), axis=0))\n",
    "\n",
    "# 2. Melt (Model to column) and Explode (expand lists into rows)\n",
    "long_flow_df = grouped.melt(id_vars='Basin', var_name='Model', value_name='CRPS').explode('CRPS')\n",
    "\n",
    "# 3. Add a Leadtime column (automatically counts 1, 2, 3... for each group)\n",
    "long_flow_df['Leadtime'] = long_flow_df.groupby(['Basin', 'Model']).cumcount() + 1\n",
    "\n",
    "# Ensure the CRPS column is numeric (explode sometimes leaves it as object)\n",
    "long_flow_df['CRPS'] = long_flow_df['CRPS'].astype(float)\n",
    "\n",
    "print(long_flow_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e37fca-1b14-47d5-9ebe-967c64ae7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_flow_df = process_crps_df(flow_crps_df, basins, 'total_flow')\n",
    "long_autoregression_df = process_crps_df(autoregression_crps_df, basins, 'autoregression')\n",
    "long_gamma_df = process_crps_df(gamma_crps_df, basins, 'gamma')\n",
    "long_num_rise_df = process_crps_df(num_rise_crps_df, basins, 'num_rise')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382185f-cbe1-4f49-aed2-3cfae336c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conditional_Flow_DF = long_flow_df[long_flow_df['Model'] == 'Conditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e2e19d-5481-41ca-84e8-233baa39ddb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basin_tables = create_basin_crps_tables(crps_per_leadtime, basins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f98a6f-7ac7-45d4-990f-f24c14c5c5c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CRPS_df = add_coordinates_to_basin_table(basin_tables['Conditional'], csv_base_path=\"/perm/mokr/Caravans/Caravan/attributes/\")\n",
    "Probabilistic_df = add_coordinates_to_basin_table(basin_tables['Probabilistic'], csv_base_path=\"/perm/mokr/Caravans/Caravan/attributes/\")\n",
    "\n",
    "Flow_df = add_coordinates_to_basin_table(long_flow_df, csv_base_path=\"/perm/mokr/Caravans/Caravan/attributes/\")\n",
    "Autoregression_df = add_coordinates_to_basin_table(long_autoregression_df, csv_base_path=\"/perm/mokr/Caravans/Caravan/attributes/\")\n",
    "Gamma_df = add_coordinates_to_basin_table(long_gamma_df, csv_base_path=\"/perm/mokr/Caravans/Caravan/attributes/\")\n",
    "NumRise_df = add_coordinates_to_basin_table(long_num_rise_df, csv_base_path=\"/perm/mokr/Caravans/Caravan/attributes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fabae-f990-46c2-8c3c-51ce11672d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all dictionaries\n",
    "Flow_dict = create_model_dict(Flow_df)\n",
    "Autoregression_dict = create_model_dict(Autoregression_df)\n",
    "Gamma_dict = create_model_dict(Gamma_df)\n",
    "NumRise_dict = create_model_dict(NumRise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328637c6-f44c-40d9-827b-890b5b73e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path=\"/home/mokr/GLOFAS_ML_Flood_Modelling/data/ne_110m_admin_0_countries/raw/ne_110m_admin_0_countries.shp\"\n",
    "world = gpd.read_file(shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d0249-cfd0-41a0-a889-5fc98f55a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on coordinates\n",
    "leadtime = 3\n",
    "merged = CRPS_df[['Basin', 'Latitude','Longitude',f'Leadtime_{leadtime}']].merge(\n",
    "    Probabilistic_df[['Basin','Latitude','Longitude',f'Leadtime_{leadtime}']],\n",
    "    on=['Basin', 'Latitude','Longitude'],\n",
    "    suffixes=(\"_CRPS\", \"_Prob\")\n",
    ")\n",
    "\n",
    "# Difference: CRPS - Probabilistic\n",
    "merged['difference'] = 1 - (merged[f'Leadtime_{leadtime}_CRPS']/merged[f'Leadtime_{leadtime}_Prob']) \n",
    "merged['abs_difference'] = merged[f'Leadtime_{leadtime}_CRPS'] - merged[f'Leadtime_{leadtime}_Prob']\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_diff = gpd.GeoDataFrame(\n",
    "    merged,\n",
    "    geometry=gpd.points_from_xy(merged.Longitude, merged.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b310f2-3a12-493f-bd86-34db29adb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flow_dict['Conditional']\n",
    "Flow_dict['Probabilistic']\n",
    "Flow_dict['Conditional'][Flow_dict['Conditional']['Location'] == 'camelscl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784859d-df0e-4563-9ef4-d9b4503b0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.sort_values('difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edd3f1-ca56-4121-a761-37eeb1627373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sort the differences\n",
    "sorted_diff = np.sort(merged['difference'])\n",
    "\n",
    "# Calculate the cumulative probabilities\n",
    "cumulative_prob = np.arange(1, len(sorted_diff) + 1) / len(sorted_diff)\n",
    "\n",
    "# Create the CDF plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_diff, cumulative_prob, linewidth=2)\n",
    "plt.xlabel('Difference (1 - CRPS/Probabilistic)', fontsize=12)\n",
    "plt.ylabel('Cumulative Probability', fontsize=12)\n",
    "plt.title('CDF of Performance Difference (CRPS vs Probabilistic)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.5, label='No difference')\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.3, label='Median')\n",
    "\n",
    "# Add median value annotation\n",
    "median_diff = np.median(merged['difference'])\n",
    "plt.axvline(x=median_diff, color='green', linestyle='--', alpha=0.5, label=f'Median: {median_diff:.4f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Summary Statistics for Difference:\")\n",
    "print(f\"Mean: {merged['difference'].mean():.4f}\")\n",
    "print(f\"Median: {median_diff:.4f}\")\n",
    "print(f\"Std Dev: {merged['difference'].std():.4f}\")\n",
    "print(f\"Min: {merged['difference'].min():.4f}\")\n",
    "print(f\"Max: {merged['difference'].max():.4f}\")\n",
    "print(f\"% of locations where CRPS < Probabilistic: {(merged['difference'] > 0).mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815847d-8037-470b-8644-cc4f3c2d87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Choose discrete difference bounds (adjust as needed) ---\n",
    "bounds = [-4, -0.25, -0.05, 0.05, 0.25, 1]\n",
    "base_cmap = plt.get_cmap('RdBu')   # diverging colormap\n",
    "n_colours = len(bounds) - 1  # Number of color segments\n",
    "colors = base_cmap([0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "# norm = mcolors.TwoSlopeNorm(0, -1, 1)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# --- 2 Subplots ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [2.35, 1]}, figsize=(20, 10))\n",
    "fig.suptitle('Conditional-LSTM CRPSS at 3-Day Leadtime', fontsize=32, fontweight='bold', y=0.91)\n",
    "\n",
    "Title_Size = 28\n",
    "Tick_Size = 22\n",
    "\n",
    "# ========== US MAP ==========\n",
    "world.plot(ax=ax1, color='lightgray', edgecolor='black')\n",
    "\n",
    "us_gdf = gdf_diff[(gdf_diff.geometry.x >= -130) & (gdf_diff.geometry.x <= -50) &\n",
    "                  (gdf_diff.geometry.y >= 25) & (gdf_diff.geometry.y <= 60)]\n",
    "\n",
    "us_gdf.plot(\n",
    "    column='difference',\n",
    "    ax=ax1,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    legend=False,\n",
    "    markersize=20\n",
    ")\n",
    "\n",
    "ax1.set_title('United States & Canada', fontsize=Title_Size)\n",
    "ax1.set_xlim([-130, -50])\n",
    "ax1.set_ylim([25, 60])\n",
    "\n",
    "# ========== BRAZIL MAP ==========\n",
    "world.plot(ax=ax2, color='lightgray', edgecolor='black')\n",
    "\n",
    "brazil_gdf = gdf_diff[(gdf_diff.geometry.x >= -75) & (gdf_diff.geometry.x <= -35) &\n",
    "                      (gdf_diff.geometry.y >= -35) & (gdf_diff.geometry.y <= 10)]\n",
    "\n",
    "brazil_gdf.plot(\n",
    "    column='difference',\n",
    "    ax=ax2,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    legend=False,\n",
    "    markersize=20\n",
    ")\n",
    "\n",
    "ax2.set_title('South America', fontsize=Title_Size)\n",
    "ax2.set_xlim([-85, -33])\n",
    "ax2.set_ylim([-60, 15])\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=Tick_Size)\n",
    "    ax.set_xlabel('Longitude', fontsize=28, fontweight='bold')\n",
    "    ax.set_ylabel('Latitude', fontsize=28, fontweight='bold')\n",
    "\n",
    "# --- Single Colorbar ---\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=Tick_Size)\n",
    "cbar.set_label(\"CRPSS\", fontsize=28, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49edec-2535-4395-b808-c2d0edad08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "metric_dicts = {\n",
    "    'Total_Flow': Flow_dict,\n",
    "    'Autocorrelation': Autoregression_dict,\n",
    "    'Gamma': Gamma_dict,\n",
    "    'NumRise': NumRise_dict\n",
    "}\n",
    "\n",
    "CRPSS_Stats = calculate_crpss('Conditional', 'Probabilistic', metric_dicts)\n",
    "\n",
    "CRPSS_Stats['Latitude'] = Flow_dict['Conditional']['Latitude'].reset_index(drop=True)\n",
    "CRPSS_Stats['Longitude'] = Flow_dict['Conditional']['Longitude'].reset_index(drop=True)\n",
    "# Convert to GeoDataFrame\n",
    "gdf_diff = gpd.GeoDataFrame(\n",
    "    CRPSS_Stats,\n",
    "    geometry=gpd.points_from_xy(CRPSS_Stats.Longitude, CRPSS_Stats.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b0653-b080-4c7f-a528-1c9c50158e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose discrete difference bounds (adjust as needed) ---\n",
    "bounds = [-2, -0.25, -0.05, 0.05, 0.25, 1]\n",
    "base_cmap = plt.get_cmap('RdBu')   # diverging colormap\n",
    "n_colours = len(bounds) - 1  # Number of color segments\n",
    "colors = base_cmap([0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "# norm = mcolors.TwoSlopeNorm(0, -1, 1)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# --- 2 Subplots ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [2.35, 1]}, figsize=(20, 10))\n",
    "fig.suptitle('CRPSS of NumRise', fontsize=24, fontweight='bold', y=0.91)\n",
    "\n",
    "Title_Size = 18\n",
    "\n",
    "# ========== US MAP ==========\n",
    "world.plot(ax=ax1, color='lightgray', edgecolor='black')\n",
    "\n",
    "us_gdf = gdf_diff[(gdf_diff.geometry.x >= -130) & (gdf_diff.geometry.x <= -50) &\n",
    "                  (gdf_diff.geometry.y >= 25) & (gdf_diff.geometry.y <= 60)]\n",
    "\n",
    "us_gdf.plot(\n",
    "    column='NumRise',\n",
    "    ax=ax1,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    legend=False,\n",
    "    markersize=20\n",
    ")\n",
    "\n",
    "ax1.set_title('US: Conditional-LSTM CRPSS', fontsize=Title_Size)\n",
    "ax1.set_xlim([-130, -50])\n",
    "ax1.set_ylim([25, 60])\n",
    "\n",
    "# ========== BRAZIL MAP ==========\n",
    "world.plot(ax=ax2, color='lightgray', edgecolor='black')\n",
    "\n",
    "brazil_gdf = gdf_diff[(gdf_diff.geometry.x >= -75) & (gdf_diff.geometry.x <= -35) &\n",
    "                      (gdf_diff.geometry.y >= -35) & (gdf_diff.geometry.y <= 10)]\n",
    "\n",
    "brazil_gdf.plot(\n",
    "    column='Total_Flow',\n",
    "    ax=ax2,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    legend=False,\n",
    "    markersize=20\n",
    ")\n",
    "\n",
    "ax2.set_title('South America: Conditional-LSTM CRPSS', fontsize=Title_Size)\n",
    "ax2.set_xlim([-85, -33])\n",
    "ax2.set_ylim([-60, 15])\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax.set_xlabel('Longitude', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Latitude', fontsize=16, fontweight='bold')\n",
    "\n",
    "# --- Single Colorbar ---\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "cbar.set_label(\"CRPSS\", fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLPlayground",
   "language": "python",
   "name": "mlplayground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
