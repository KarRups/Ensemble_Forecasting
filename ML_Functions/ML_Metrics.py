"""
FILE CONTENTS
================================================================================

FUNCTIONS:
--------------------------------------------------------------------------------
# Helper Functions
 1. safe_corrcoef
    No description available

# Basic Metrics (NSE, KGE)
 2. calculate_nse
    Calculate Nash-Sutcliffe Efficiency
 3. calculate_kge
    Calculate Kling-Gupta Efficiency

# CRPS Functions
 4. compute_crps
    Calculate the Continuous Ranked Probability Score (CRPS).
 5. compute_crps_np
    Calculate the Continuous Ranked Probability Score (CRPS).
 6. calculate_overall_crps
    Calculate CRPS for each feature across all prediction instances
 7. calculate_model_crps
    Calculate CRPS for multiple models
 8. calculate_crps_with_ci
    Calculate CRPS with confidence intervals for multiple models
 9. calculate_crpss
    Calculate CRPSS (Continuous Ranked Probability Skill Score) for multiple metr...

# Variogram Scores
10. variogram_score_torch
    The variogram score is the mean squared error between the empirical variogram
11. variogram_score
    Calculate the variogram score for ensemble predictions.

# Ensemble Summaries
12. get_member_summaries_torch
    Returns statistical summaries for the hydrographs generated by each of the en...
13. get_member_summaries
    Returns statistical summaries for the hydrographs generated by each of the en...

# Dispersion Analysis
14. get_dispersion_calculations
    Returns a DataFrame showing the distribution of ensemble ranks.
15. count_zero_variance
    No description available
================================================================================
"""

import numpy as np
from scipy import stats
import torch

def safe_corrcoef(x, y, tolerance=1e-6):
    x = np.array(x)
    y = np.array(y)
    
    # Check if standard deviations are close to zero
    if np.std(x) < tolerance or np.std(y) < tolerance:
        return 1.0
    
    # If there is variance, compute the correlation coefficient
    # Ensure there's enough data for correlation
    if len(x) < 2 or len(y) < 2:
        return 1.0 # Or np.nan, depending on desired behavior for small samples
    
    return np.corrcoef(x, y)[0, 1]


def calculate_nse(observations, forecasts, epsilon=1e-8):
    """
    Calculate Nash-Sutcliffe Efficiency
    NSE = 1 - (sum of squared errors / sum of squared deviations from mean)
    
    Parameters:
    - observations: array of observed values
    - forecasts: array of forecasted values
    - epsilon: regularization parameter to prevent division by zero
    
    Returns:
    - NSE value
    """
    # Convert to numpy arrays
    observations = np.array(observations)
    forecasts = np.array(forecasts)
    
    # Remove NaN values
    mask = ~(np.isnan(observations) | np.isnan(forecasts))
    obs_clean = observations[mask]
    fcst_clean = forecasts[mask]
    
    # Calculate NSE with numerical stability
    numerator = np.sum((obs_clean - fcst_clean) ** 2)
    denominator = np.sum((obs_clean - np.mean(obs_clean)) ** 2)
    nse_value = 1 - (numerator / (denominator + epsilon))
    
    return nse_value


def calculate_kge(observations, forecasts, epsilon=1e-8, use_safe_corrcoef=True):
    """
    Calculate Kling-Gupta Efficiency
    KGE = 1 - sqrt((r-1)^2 + (gamma-1)^2 + (beta-1)^2)
    
    Parameters:
    - observations: array of observed values
    - forecasts: array of forecasted values
    - epsilon: regularization parameter to prevent division by zero
    - use_safe_corrcoef: if True, uses safe_corrcoef function; otherwise uses np.corrcoef
    
    where:
    r = correlation coefficient
    gamma = std(sim) / std(obs) (variability ratio)
    beta = mean(sim) / mean(obs) (bias ratio)
    
    Returns:
    - KGE value
    """
    # Convert to numpy arrays
    observations = np.array(observations)
    forecasts = np.array(forecasts)
    
    # Remove NaN values
    mask = ~(np.isnan(observations) | np.isnan(forecasts))
    obs_clean = observations[mask]
    fcst_clean = forecasts[mask]
    
    # Calculate correlation
    if use_safe_corrcoef:
        r = safe_corrcoef(fcst_clean, obs_clean, tolerance=epsilon)
    else:
        r = np.corrcoef(obs_clean, fcst_clean)[0, 1]
    
    # Calculate components with numerical stability
    gamma = np.std(fcst_clean) / (np.std(obs_clean) + epsilon)  # Variability ratio
    beta = np.mean(fcst_clean) / (np.mean(obs_clean) + epsilon)  # Bias ratio
    
    # Calculate KGE
    kge_value = 1 - np.sqrt((r - 1)**2 + (gamma - 1)**2 + (beta - 1)**2)
    
    return kge_value


def compute_crps(forecasts, observation, epsilon=0.0):
    """
    Calculate the Continuous Ranked Probability Score (CRPS).
    
    Parameters:
    - forecasts: numpy array of ensemble forecasts, shape (n_members,)
    - observation: scalar true observation
    
    Returns:
    - CRPS score (lower is better)
    """
    # Sort the forecasts
    forecasts[forecasts < -0.26787253] = -0.2678725
    n_members, batch_size, num_steps = forecasts.shape
    forecasts_reshaped = forecasts.permute(1, 2, 0)


   # Reshape observations
    
    observations_expanded = observation.unsqueeze(-1)
    
    term1 = torch.abs(forecasts_reshaped - observations_expanded).mean(dim= -1)

    if torch.isnan(term1).any() or torch.isinf(term1).any():
        print("=== TERM1 ERROR ===")
        print(f"Term1 - NaN: {torch.isnan(term1).sum()}, Inf: {torch.isinf(term1).sum()}")

    
    x_j = forecasts_reshaped.unsqueeze(3)  # (batch_size, num_steps, n_members, 1)
    x_k = forecasts_reshaped.unsqueeze(2)  # (batch_size, num_steps, 1, n_members)
    pairwise_diffs = torch.abs(x_j - x_k)
    term2 = pairwise_diffs.sum(dim=(2, 3))/(2* n_members * (n_members-1) )

    if torch.isnan(term2).any() or torch.isinf(term2).any():
        print("=== TERM2 ERROR ===")
        print(f"Term2 - NaN: {torch.isnan(term2).sum()}, Inf: {torch.isinf(term2).sum()}")
        print(f"Pairwise_diffs range: {pairwise_diffs.min():.6f} to {pairwise_diffs.max():.6f}")

    
    crps_scores = term1 - ((1 - epsilon)* term2)

    return crps_scores


def compute_crps_np(forecasts, observation, epsilon=0.0):
    """
    Calculate the Continuous Ranked Probability Score (CRPS).
    
    Parameters:
    - forecasts: numpy array of ensemble forecasts, shape (n_timesteps, n_members) or (n_members, batch_size, num_steps)
    - observation: numpy array of true observations, shape (n_timesteps,) or (batch_size, num_steps)
    - epsilon: regularization parameter
    
    Returns:
    - CRPS scores, shape (n_timesteps,) or (batch_size, num_steps)
    """
    # Handle both input formats
    if forecasts.ndim == 2:
        # Input format: (n_timesteps, n_members)
        # Convert to: (n_members, 1, n_timesteps)
        forecasts = forecasts.T[:, np.newaxis, :]
        observation = observation[np.newaxis, :]
    
    # Clip forecasts
    forecasts = np.clip(forecasts, a_min=-0.26787253, a_max=None)
    
    num_steps, batch_size, n_members  = forecasts.shape
    forecasts_reshaped = np.transpose(forecasts, (1, 2, 0))  # (batch_size, num_steps, n_members)
    
    # Reshape observations
    observations_expanded = observation[..., np.newaxis]  # (batch_size, num_steps, 1)

    
    # Term 1: Mean absolute difference between forecasts and observation
    term1 = np.abs(forecasts_reshaped - observations_expanded).mean(axis=-1)
    if np.isnan(term1).any() or np.isinf(term1).any():
        print("=== TERM1 ERROR ===")
        print(f"Term1 - NaN: {np.isnan(term1).sum()}, Inf: {np.isinf(term1).sum()}")
    
    # Term 2: Mean pairwise absolute difference between ensemble members
    x_j = forecasts_reshaped[:, :, :, np.newaxis]  # (batch_size, num_steps, n_members, 1)
    x_k = forecasts_reshaped[:, :, np.newaxis, :]  # (batch_size, num_steps, 1, n_members)
    pairwise_diffs = np.abs(x_j - x_k)
    term2 = pairwise_diffs.sum(axis=(2, 3)) / (2 * n_members * (n_members - 1))
    if np.isnan(term2).any() or np.isinf(term2).any():
        print("=== TERM2 ERROR ===")
        print(f"Term2 - NaN: {np.isnan(term2).sum()}, Inf: {np.isinf(term2).sum()}")
        print(f"Pairwise_diffs range: {pairwise_diffs.min():.6f} to {pairwise_diffs.max():.6f}")
    
    crps_scores = term1 - ((1 - epsilon) * term2)
    
    # Return in original shape format
    if crps_scores.shape[0] == 1:
        crps_scores = crps_scores.squeeze(0)  # (num_steps,)
    
    return crps_scores


def calculate_overall_crps(ensemble_predictions, true_flow, 
                          features=['total_flow', 'variance', 'gradient', 'autoregression'], return_mean = True):
    """
    Calculate CRPS for each feature across all prediction instances
    
    Parameters:
    - ensemble_predictions: Dictionary with ensemble arrays of shape (n_timesteps, n_members)
    - true_flow: Dictionary with true flow arrays of shape (n_timesteps,) or (n_timesteps, 1)
    
    Returns:
    - Dictionary with mean CRPS scores for each feature
    """
    crps_scores = {}
    
    for feature in features:
        if feature not in ensemble_predictions or feature not in true_flow:
            print(f"Warning: Feature '{feature}' not found in data")
            continue
            
        forecasts = ensemble_predictions[feature][:, :] 
        observations = true_flow[feature][:,0] 
        
        # Ensure observations are 1D if they're 2D with single column
        if len(observations.shape) == 2 and observations.shape[1] == 1:
            observations = observations.squeeze(-1)
        
        # Compute CRPS for each timestep
        crps_values = []
        crps_value = compute_crps_np(forecasts, observations)
        crps_values.append(crps_value)
        
        # Store mean CRPS for this feature
        crps_scores[feature] = np.mean(crps_values)
        if return_mean:
            crps_scores[feature] = np.mean(crps_values)
        else:
            crps_scores[feature] = np.concatenate(crps_values) if len(crps_values) > 1 else crps_values[0]

    return crps_scores


def calculate_model_crps(ensemble_summaries, model_names, 
                         metrics=['total_flow', 'variance', 'autoregression', 'fdc_curve'], return_mean=True):
    """
    Calculate CRPS for multiple models
    
    Parameters:
    - ensemble_summaries: Dictionary containing model predictions and discharge data
    - model_names: List of model names to evaluate
    - metrics: List of features to compute CRPS for
    
    Returns:
    - Dictionary with CRPS scores for each model
    """
    model_crps = {}
    
    for model_name in model_names:
        if model_name in ensemble_summaries and 'Discharge' in ensemble_summaries:
            model_crps[model_name] = calculate_overall_crps(
                ensemble_summaries[model_name], 
                ensemble_summaries['Discharge'], 
                features=metrics,
                return_mean=return_mean
            )
        else:
            print(f"Warning: Model '{model_name}' or 'Discharge' not found in ensemble_summaries")
    
    return model_crps


def calculate_crps_with_ci(ensemble_summaries, model_names, metrics, confidence=0.95):
    """
    Calculate CRPS with confidence intervals for multiple models
    
    Returns:
    - Dictionary with mean CRPS and confidence intervals for each model
    """
    model_crps_mean = {}
    model_crps_ci = {}
    
    for model_name in model_names:
        if model_name in ensemble_summaries and 'Discharge' in ensemble_summaries:
            # Get individual CRPS values (not means)
            crps_individual = calculate_overall_crps(
                ensemble_summaries[model_name], 
                ensemble_summaries['Discharge'], 
                features=metrics,
                return_mean=False  # Get individual values
            )
            
            model_crps_mean[model_name] = {}
            model_crps_ci[model_name] = {}
            
            for metric in metrics:
                values = crps_individual[metric]
                
                # Calculate mean
                mean_val = np.mean(values)
                
                # Calculate confidence interval
                # Using bootstrap or standard error
                n = len(values)
                std_err = stats.sem(values)  # Standard error of the mean
                ci = std_err * stats.t.ppf((1 + confidence) / 2, n - 1)
                
                model_crps_mean[model_name][metric] = mean_val
                model_crps_ci[model_name][metric] = ci
        else:
            print(f"Warning: Model '{model_name}' or 'Discharge' not found")
    
    return model_crps_mean, model_crps_ci


def calculate_crpss(conditional_dict, probabilistic_dict, metric_dicts):
    """
    Calculate CRPSS (Continuous Ranked Probability Skill Score) for multiple metrics.
    
    Parameters:
    -----------
    conditional_dict : str
        Name of the conditional model in the dictionaries
    probabilistic_dict : str
        Name of the probabilistic (baseline) model in the dictionaries
    metric_dicts : dict
        Dictionary mapping metric names to their corresponding model dictionaries
        e.g., {'Total_Flow': Flow_dict, 'Autocorrelation': Autoregression_dict}
    
    Returns:
    --------
    pd.DataFrame
        DataFrame with CRPSS for each metric
    """
    CRPSS_Stats = pd.DataFrame()
    
    for metric_name, model_dict in metric_dicts.items():
        CRPSS_Stats[metric_name] = 1 - (
            model_dict[conditional_dict]['CRPS'].reset_index(drop=True) / 
            model_dict[probabilistic_dict]['CRPS'].reset_index(drop=True)
        )
    
    return CRPSS_Stats


def variogram_score_torch(ensemble_predictions, true_values, p=1.0):
    """    
    The variogram score is the mean squared error between the empirical variogram
    of the ensemble and the variogram of the observations:
    
    VS = (1/T^2) * sum_i sum_j (E[|X_i - X_j|^p] - |Y_i - Y_j|^p)^2
    
    where X are ensemble members, Y are observations, i,j index time steps, 
    and E is the expectation over ensemble members.
    
    Parameters:
    -----------
    ensemble_predictions : torch.Tensor
        Shape (n_ensemble, n_features, n_timesteps)
        Ensemble forecast predictions
    true_values : torch.Tensor
        Shape (n_features, n_timesteps)
        True observed values
    p : float, default=1.0
        Power parameter for the variogram (typically 0.5 or 1.0)
    
    Returns:
    --------
    vs : torch.Tensor
        Variogram score (0 is perfect)
    """
    # Reshape
    ensemble = ensemble_predictions.squeeze(dim=1)  # (n_ensemble, n_timesteps)
    true = true_values.squeeze(dim=0)  # (n_timesteps,)
    
    n_ensemble, n_timesteps = ensemble.shape
    
    # Compute pairwise differences for ensemble: |X_i - X_j|^p
    # Shape: (n_ensemble, n_timesteps, n_timesteps)
    ens_i = ensemble.unsqueeze(2)  # (n_ensemble, n_timesteps, 1)
    ens_j = ensemble.unsqueeze(1)  # (n_ensemble, 1, n_timesteps)
    pairwise_ens = torch.abs(ens_i - ens_j) ** p  # (n_ensemble, n_timesteps, n_timesteps)


    
    # Average over ensemble members: E[|X_i - X_j|^p]
    # Shape: (n_timesteps, n_timesteps)
    ensemble_variogram = torch.mean(pairwise_ens, dim=0)
    
    # Compute pairwise differences for observations: |Y_i - Y_j|^p
    # Shape: (n_timesteps, n_timesteps)
    true_i = true.unsqueeze(1)  # (n_timesteps, 1)
    true_j = true.unsqueeze(0)  # (1, n_timesteps)
    true_variogram = torch.abs(true_i - true_j) ** p  # (n_timesteps, n_timesteps)

    
    # Variogram score: MSE between ensemble and true variograms
    individual_scores = (ensemble_variogram - true_variogram) ** 2
    vs = torch.mean((ensemble_variogram - true_variogram) ** 2)
    
    return vs


def variogram_score(ensemble_predictions, true_values, p=1.0):
    """
    Calculate the variogram score for ensemble predictions.
    
    The variogram score measures the difference between the empirical variogram
    of the ensemble and the variogram between observations and ensemble.
    
    VS = E[|X_i - X_j|^p] - E[|Y_i - Y_j|^p]
    
    where X are ensemble members, Y are observations, and i,j index time steps.
    
    Parameters:
    -----------
    ensemble_predictions : np.ndarray
        Shape (n_ensemble, n_features, n_timesteps)
        Ensemble forecast predictions
    true_values : np.ndarray
        Shape (n_features, n_timesteps)
        True observed values
    p : float, default=1.0
        Power parameter for the variogram (typically 0.5 or 1.0)
    
    Returns:
    --------
    vs : float
        Variogram score (lower is better, 0 is perfect)
    """
    # Reshape
    ensemble = ensemble_predictions.squeeze(axis=1)  # (n_ensemble, n_timesteps)
    true = true_values.squeeze(axis=0)  # (n_timesteps,)
    
    n_ensemble, n_timesteps = ensemble.shape
    
    # Term 1: Average variogram within ensemble E[|X_i - X_j|^p]
    ens_i = ensemble[:, :, np.newaxis]  # (n_ensemble, n_timesteps, 1)
    ens_j = ensemble[:, np.newaxis, :]  # (n_ensemble, 1, n_timesteps)
    pairwise_ens = np.abs(ens_i - ens_j) ** p  # (n_ensemble, n_timesteps, n_timesteps)
    
    ensemble_variogram = np.mean(pairwise_ens, axis=0)

    # Compute pairwise differences for observations: |Y_i - Y_j|^p
    # Shape: (n_timesteps, n_timesteps)
    true_i = true[:, np.newaxis]  # (n_timesteps, 1)
    true_j = true[np.newaxis, :]  # (1, n_timesteps)
    true_variogram = np.abs(true_i - true_j) ** p  # (n_timesteps, n_timesteps)
    
    # Variogram score: MSE between ensemble and true variograms
    vs = np.mean((ensemble_variogram - true_variogram) ** 2)
    
    return vs


def get_member_summaries_torch(ensembles):
    ''' Returns statistical summaries for the hydrographs generated by each of the ensemble members  
    '''
    import torch
    
    # Assuming ensembles is already a torch tensor with shape [num_members, num_batches, num_steps]
    num_members, num_batches, num_steps = ensembles.shape
    

    
    ensembles_summaries = {}
    
    # Total flow - sum along the time dimension
    ensembles_summaries['total_flow'] = torch.sum(ensembles, dim=-1)
    
    # Variance along the time dimension
    ensembles_summaries['variance'] = torch.var(ensembles, dim=-1)
    ensembles_summaries['gamma'] = torch.std(ensembles, dim=-1)/(torch.mean(ensembles, dim=-1) + 1e-8)
    
    # For gradient calculation with polyfit, you might want to use a PyTorch-compatible method
    # or fall back to numpy for this specific calculation
    
    # Autoregression calculation
    current = ensembles[:, :, 1:]  # Shape: (num_members, num_batches, num_steps-1)
    lagged = ensembles[:, :, :-1]  # Shape: (num_members, num_batches, num_steps-1)
    
    # Calculate means along time dimension for each member and batch
    current_mean = torch.mean(current, dim=-1, keepdim=True)  # Shape: (num_members, num_batches, 1)
    lagged_mean = torch.mean(lagged, dim=-1, keepdim=True)    # Shape: (num_members, num_batches, 1)
    
    # Calculate cross-covariance between current and lagged for each member and batch
    cross_cov = torch.mean((current - current_mean) * (lagged - lagged_mean), dim=2)  # Shape: (num_members, num_batches)
    
    # Calculate variance of current and lagged for each member and batch
    var_current = torch.mean((current - current_mean)**2, dim=-1)  # Shape: (num_members, num_batches)
    var_lagged = torch.mean((lagged - lagged_mean)**2, dim=-1)     # Shape: (num_members, num_batches)
    
    # Initialize ar_coeffs tensor with zeros
    ar_coeffs = torch.zeros((num_members, num_batches), device=ensembles.device)
    
    # Calculate correlation coefficients, handling zero variance cases
    nonzero_mask = (var_current > 0) & (var_lagged > 0)
    ar_coeffs[nonzero_mask] = cross_cov[nonzero_mask] / torch.sqrt(var_current[nonzero_mask] * var_lagged[nonzero_mask])
    
    ensembles_summaries['autoregression'] = ar_coeffs
    ensembles_summaries['num_rise'] = (ensembles[..., :-1] > ensembles[..., 1:]).sum(dim=tuple(range(1, ensembles.ndim))).float().unsqueeze(-1)
    
    # FDC curve calculation
    sorted_ensembles, _ = torch.sort(ensembles, dim=-1)
    ensembles_summaries['fdc_curve'] = (torch.log(sorted_ensembles[:, :, 7] + 1e-8) - torch.log(sorted_ensembles[:, :, 2] + 1e-8)) / 5
    
    return ensembles_summaries


def get_member_summaries(ensembles, scaler_path='/home/mokr/Loss_Functions_Paper/Scalers/discharge_caravan_scalers.joblib'):
    ''' Returns statistical summaries for the hydrographs generated by each of the ensemmble members  
    '''

    ensembles, _ = load_and_unnormalize(ensembles,ensembles,scaler_path)
    ensembles_summaries = {}
    ensembles_summaries['total_flow'] = np.sum(ensembles, axis = 1)
    ensembles_summaries['variance'] = np.var(ensembles, axis = 1)
    x = np.arange(ensembles.shape[1])  # Lead times
    ensembles_summaries['gradient'] = np.array([np.polyfit(x, ensemble, 1)[0] for ensemble in ensembles])


    ar_coeffs = []  # Create a list to store the coefficients

    for i in range(len(ensembles)):
        # Calculate covariance matrix
        cov_matrix = np.cov(ensembles[i, 1:], ensembles[i, 0:-1])
    
        if cov_matrix[0,0] > 0 and cov_matrix[1,1] > 0:
            ar_coeff = cov_matrix[0,1] / (np.sqrt(cov_matrix[0,0]*cov_matrix[1,1]))
        else:
            ar_coeff = 0
        ar_coeffs.append(ar_coeff)

    ensembles_summaries['autoregression'] = np.vstack(ar_coeffs)

    ensembles_summaries['num_rise'] = np.sum(ensembles.squeeze()[:, :-1] > ensembles.squeeze(-1)[:, 1:], axis=1)

    ensembles_summaries['fdc_curve'] = ( np.log(np.sort(ensembles, axis = -1)[:,7] + 0.2678726) - np.log(np.sort(ensembles, axis = -1)[:, 2] + 0.2678726) )/5
    return ensembles_summaries


def get_dispersion_calculations(ensemble_summaries, truth):
    '''
    Returns a DataFrame showing the distribution of ensemble ranks.
    A rank is the number of ensemble members that underpredicted the truth.
    For a well-calibrated ensemble, this distribution should be flat.
    
    Parameters:
    ensemble_summaries: Dictionary with structure {model: {stat: array}}
                       where each array has shape (num_locations, num_members)
    truth: A list of dictionaries with observed data statistics matching the keys.
    
    Returns:
    DataFrame with the percentage of time each rank (0, 1, ..., N) occurred.
    '''
    # Get the first model and stat to determine num_members
    first_model = next(iter(ensemble_summaries))
    first_stat = next(iter(ensemble_summaries[first_model]))
    # The array has shape (num_locations, num_members) so we get shape[1]
    num_members = ensemble_summaries[first_model][first_stat].shape[1]
    num_bins = num_members + 1
    
    # Labels represent the number of members underpredicting the truth
    bin_labels = [f"{i}" for i in range(num_bins)]
    
    # Initialize dictionary to store all ranks for each model-statistic combination
    all_ranks = {}
    
    # Iterate through each model
    for model_name, model_stats in ensemble_summaries.items():
        # Iterate through each statistic
        for stat_name, stat_array in model_stats.items():
            # Create a key combining model and stat
            combined_key = f"{model_name}_{stat_name}"
            all_ranks[combined_key] = []
            
            # Iterate through each location
            for location_idx in range(len(truth[stat_name])):
                ensemble_stat = stat_array[location_idx]
                truth_val = truth[stat_name][location_idx]
                
                # Calculate rank - the proportion of members smaller than the truth
                rank_proportion = np.mean((ensemble_stat < truth_val).astype(float))
                all_ranks[combined_key].append(rank_proportion.item())
    
    # Compute the histogram for each statistic
    dispersion_results = {}
    for key, ranks in all_ranks.items():
        # Convert rank proportions (0.0 to 1.0) to rank counts (0 to N)
        rank_counts = np.round(np.array(ranks) * num_members)
        
        # Use torch.histc for a direct, efficient count of integer ranks
        hist, _ = np.histogram(rank_counts, bins=num_bins, range=(0, num_members))        
        
        # Convert counts to percentages
        total_ranks = len(ranks)
        if total_ranks > 0:
            dispersion_results[key] = (hist / total_ranks * 100).tolist()
        else:
            dispersion_results[key] = [0.0] * num_bins
    
    return pd.DataFrame(dispersion_results, index=bin_labels)    


def count_zero_variance(ensemble_summaries, model_name='Discharge', threshold=1e-7):
    zero_count = 0
    total_count = 0
    zero_indices = []
    
    for i in range(len(ensemble_summaries[model_name])):
        variance = ensemble_summaries[model_name][i]['variance']
        
        # Handle case where variance might be a list/array
        if hasattr(variance, '__iter__') and not isinstance(variance, str):
            variances = np.array(variance)
            zero_in_sample = np.sum(np.abs(variances) <= threshold)
            if zero_in_sample > 0:
                zero_indices.append(i)
            zero_count += zero_in_sample
            total_count += len(variances)
        else:
            if abs(variance) <= threshold:
                zero_count += 1
                zero_indices.append(i)
            total_count += 1
    
    percentage = (zero_count / total_count) * 100 if total_count > 0 else 0
    
    return {
        'zero_count': zero_count,
        'total_count': total_count,
        'percentage': percentage,
        'zero_indices': zero_indices
    }
